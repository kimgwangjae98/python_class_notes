브로드 캐스팅은 간단하게 말하면 자동으로 길이를 맞춰준다.
넘파이는 명시적으로 import numpy as np 로 설정함. 보통 앞글자 따서 설정함. 넘파이는 대응하는 성분끼리 연산하는 벡터라이제이션 기능을 탑재함. 참고로 파이썬도 벡터라이제이션 지원함. 벡터라이제이션도 각 원소끼리 연산이 가능하게 만들어주는 기능?임. ndarray는 n차원의 배열(차원)임. 가로는 열, 세로는 행.(가열세행). 가로줄의 갯수는 행, 세로줄의 갯수는 열. m*n은 가로줄 갯수가 m, 세로줄 갯수가 n인 행렬. 1열의 값은 1,4이고 1행의 값은 1,2,3이다. array는 깊은 복사, asarray는 얕은 복사이다. 그리고 array의 타입도 설정해줄 수 있다. .shape는 행렬 형태 알 수 있고 튜플로 반환함. a[2]는 2행 출력을, a[3][2]는 3행 2열의 원소를, a[1][2][3]은 z의 1번째 2행 3열의 원소를 출력한다. (z,x,y) 형식임. 넘파이랑 오픈cv 3차원 행렬의 형식이 다르니까 shape로 형태를 꼭 확인해야 오류를 방지할 수 있음. 넘파이가 더 빠르다!, 1차원 배열은 (m,)로 출력됨을 주의할것. (m,)와 (m,1)은 다르지만 수학적 연산은 같다. reshape는 값만 가져오는 얕은 복사임. 슬라이싱도 중요함. 

산술 연산과 브로드캐스팅이 넘파이의 꽃이자 오늘 배울 중요한 개념임.
산술 연산은 사칙연산을 말함. 벡터의 사칙연산은  덧셈 뺄셈 내적 외적 이렇게 네개임. * 는 스칼라 곱셈을 의미함.  벡터 곱셈을 . 으로 씀. 배열의 사칙연산은 크기가 같아야 가능함. 크기가 다르면 계산이 안되나? -> 이게 브로드캐스팅(크기 자동 맞춤)이다. 브로드캐스팅은 대신 조건이 있음. 한쪽이 1이거나 둘다 같은 값이어야함. 차원 맞추기는 왼쪽에 1추가해서 늘림.  (m,)은 (1,m)으로 늘려줌. m앞에 1들이 추가됨. 브로드캐스팅은 스칼라연산, 벡터연산 가능 조건이 다름. 스칼라 연산 가능 조건은 크기가 완전 같아야하고, 벡터 연산 가능 조건은 m*n, n*k 로 서로 이어져야됨. 크기가 완전히 같아도 되지. 스칼라랑 벡터 곱셈은 서로 독립적임. 브로드케스팅은 스칼라에서만 일어남. 즉슨 브로드캐스팅을 한다고 해서 모든 연산이 가능한건 아니다! 일부 경우에만 가능하다. 모양만 보고 가능하다. 브로드캐스팅은 신경망에서 필터를 적용할 때 사용됨. 스칼라곱을 해야 되서 차원이 안맞는 경우 브로드캐스팅이 일어남. 1 추가해주는 브로드캐스팅 기능은 값을 유지할려고 추가하는 것임. 사실창 필터 복사임.

3차원 공간은 VTK/ITK 를 사용하여 그림. 그냥 다 그릴 수 있다.

벡터는 크기와 방향을 가짐. 크기 n인 벡터는 n개의 원소를 가진 배열로 봄. x = [n]^T 로 대충 봄. 벡터는 사실 무한히 분해가 가능함. 그리고 벡터도 행렬이라 행렬도 분해가 가능하다. 열벡터, 행벡터 란 형태가 있음. 열벡터는 세로, 행벡터는 가로임. 전치(transpose)는 행과 열을 바꾸는 연산이다. 행렬곱을 할 때 형태를 맞출려고 쓰기도함. a^T로 표기. (1,3) -> (3,1) 로 바꿔버림. 크기와 방향이 같으면 같은 벡터이다. 그저 시작점만 다를 뿐이다. 단위벡터는 크기가 1인 벡터임. i,j,k 로 표기함. a=3i+4j+6k 이런 식으로. 벡터 덧셈은 두 벡터 크기가 같을 때 스칼라처럼 더하기가 가능하다. 내적은 안쪽으로 곱한다, 외적은 바깥으로 곱한다는 뜻이다. 내적은 안에 있는 것들끼리 곱한다(크기, 방향끼리), 외적은 벡터 그 자체를 곱하는 것. 내적은 벡터를 분해해서 크기와 방향의 값을 가져와 곱한다. 외적은 크기와 방향가진 벡터 자체끼리 곱한다는거. 내적은 스칼라로, 외적은 벡터로 결과가 나옴.

내적 : 안으로 쌓는다. 벡터의 내부의 관계(원소드르이 집합)를 곱함. 두 벡터의 내용물인 원소가 얼마나 같은 정도. dot product. 화살로 비유한거 옛날에 전자기학 배울 때 들은 내용이네.
외적 : 밖으로 쌓는다. 벡터의 외부(벡터가 나타내는 선)의 관계를 곱함. 선*선=면 이란 결과가 나옴. 두 벡터가 만드는 면이 얼마나 커는 정도. cross product

1. 벡터의 연산
1-1 내적 (dot product)
    정의 : 두 벡터가 크기와 방향의 관계를 고려하여 *스칼라값*을 반환하는 연산.
    두 벡터가 서로의 방향이 얼마나 "내부적"으로 비슷한지 정도를 나타냄. 즉슨 두 벡터가 서로 얼마나 평행한지 나타냄. 
    A.B = A와 B의 크기의 곱에 cos값을 취한 값. cos값은 A와 B의 각도임. 
1-2 외적 (cross product)
    정의 : 두 벡터의 방향을 고려하여 새로운 *벡터*를 만들어내는 연산
    두 벡터의 '외부'에 새로운 벡터가 생성됨. 즉슨 두 벡터가 이루는 평면에 수직인 벡터를 나타냄.

이미지*이미지를 내적으로 했을 때, 값이 크게 나오는 곳은 동일한 정도가 크다. 이런 방식으로 사진을 비교할 수 있다. 동일한 사진이면 크기가 가장 크게 나올 것. 외적은 이미지에서 새로운 특징을 가진 이미지 뽑아냄. 벡터합성이라고도 함. 새로운 벡터는 앞의 두 벡터에 영향을 안받는 벡터이다. 외적은 트랜스포머 연산을 할 때 사용함. 완전히 새로운 벡터가 나온다. 소리가 이미지로 나올 수 있음. 내적은 두 벡터가 얼마나 유사한지, 외적은 새로운 벡터를 뽑아내는걸로 알면 된다.  공학은 의미만 알고, 왜 쓰는지만 알면 됨. 

벡터의 곱셈 = 내적
전치는 행과 열 바꾸는데 x.T 이렇게 쓰거나 np.transpose(x)로 씀. 함수로 쓰길 권장함. 안그럼 가독성이 떨어짐. 
항등 행렬은 대각선 원소만 1이고 나머지는 0인 행렬. 단위 벡터할 때 봤음.
100
010
001
은 x,y,z 단위벡터 합친거. AI=IA=A. np.eye(1) 하면 위 행렬이 나옴.
역행렬은 AB=BA=I, A가 정사각 행렬일 때 A의 역행렬을 A^-1 라고 하고, 역행렬이 존재하지 않는 행렬을 '특이 행렬' 이라고 부름. np.linalg.inv(A) 이렇게 써서 역행렬 구함.

선형 결합은 c1x1+...cnxn일때를 말함. 결과물의 형태가 식의 형태와 같아야됨. 즉슨, 벡터의 크기가 같아야됨. 그러니까 차원이 같아야됨.
선형 독립은 결과물이 완전 새로운 것이다. 선형 종속은 결과물이 이전 a로 결과물을 만들 수 있다...그러니까 결과물이 x1~xn의 조합이면 선형 종속, 아니면 선형 독립. c1x1+...cnxn=0 이면 선형 종속이다!!! 완전 새로운 결과물은... 이전에 배운 외적으로 만든다. 즉슨 선형 독립은 외적을 통해 만들어진다. 사실 거의다 종속임. 외적만이 선형 독립이다(x1+2x2 = x1 x 2x2 이면... 사실 식 성립이 불가능하지.). 그런데 독립인 경우는 매우 드물다. 그런데 이걸 왜 선형 독립인지 종속인지 판단해야되지? 간단하다. '우리가 정의한 특징 벡터가 분해될 수 있냐 없느냐를 알기 위함'

선형 결합(linear combine)
    정의 : 여러 벡터의 합으로 새로운 벡터를 표현, 만약 여러 벡터들 중에서 특정 벡터가 다른 벡터와 선형결합으로 표현된다면 그 벡터들의 선형 종속이다.
    => 독립과 기저를 정의하기 위함임, + 기호는 덧셈이 아니라 붙어있다는 뜻임.

랭크(rank)
    정의 : 여러 벡터들로 포함된 집합이 생성할 수 있는 공간의 차원의 갯수
    =>특징 : 랭크는 그 행렬에서 선형 독립인 행이나 열벡터의 갯수

여러벡터
12145
24376
=
[12145
24376]
표현이 이렇지 계산은 안함.
이거는 선형 독립이 3개임(랭크가 3개 = 3차원 만들 수 있음. 랭크가 여러벡터 수와 같으면 해가 1개. 랭크가 여러벡터 수보다 작으면 해가 무수히 많거나 없다). 선형 종속이 3개임. 즉 위 여러벡터는 해가 무수히 많거나 없다!. 12에 5를 곱하고 13을 빼면 47이 나옴. 그러니까 종속이 3개다.
2   는  1   에 2를 곱해서 나오니 선형 종속
4       2
선형 독립이면 해가 하나
선형 종속이면 해가 없거나 무수히 많음. 어쨌든 형태가 같아서 해가 안나오지...
23
46
이면 해가 없다. 

벡터 공간은 쉽게 말하자면, 선형 결합으로 만들어진 공간. 즉슨 벡터 여러개 붙여놓아 만든거를 벡터 공간이라고 함. 위에 []로 묶어둔 것이 벡터 공간.
부분 공간은 벡터 공간의 일부를 말함. 경우의 수 다 합친거임.

선형 결합 그거 의미, 랭크 의미, 선형 종속, 선형 독립 도 알기