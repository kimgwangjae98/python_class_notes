다중분류학습을 배울 것임. 이거는 전과 다름. 전에는 이진 분류기로 yes or no 로 나눴는데 이젠 아님. 다수의 이진 분류기를 학습시켜서 다중분류를 처리함. 예측 결과를 앙상블(여러개 합침. 서로다른 네트워크)하여 결과를 얻음. 앙상블 방법은 스스로 결정하면 됨. 

클래스 불균형 문제가 있음. 이건 난제. imbalance임. 아무거나 뽑아도 정답률 높아지는 문제가 있음. 그리고 학습하기 굉장히 어려울 뿐만 아니라 학습해도 테스트셋이 적으면 어쨌든 맞췄다고 판단을 내리기도함. 그래서 학습과 테스트 둘 다 영향을 미치지. 해결방법?으로 적은쪽을 복제(오버샘플링. 똑같은거라 효과가 별로 없음. 그래서 복제하고 왜곡시키는 방법을 쓰기도함)하거나 많은쪽을 삭제(언더샘플링)한다. 그러니까 클래스 불균형 문제는 심각한거다. 클래스가 모두 정규분포를 띄도록 선정해야 한다고 알기.

머신러닝의 기본인 의사결정 트리를 배움. 머신러닝 학습법에 한 종류임. 분기점에서 특징 기준에 따라 데이터들이 나눠짐. 노드(점)가 있고 분기점이 있음. 가지를 브랜치라고함. 분할 문제(지도)에서, 데이터를 분기점에서 나눌 때 무엇을 해야 잘 나누엇다고 소문이 날까? 기준에 따라 나눠야 한다. 그 기준이 순도(purity, 즉 entropy 불순도 무질서도)임. 불순도 25%이면 이 클래스에 다른 클래스가 넷 중에 하나가 섞여있다. 이렇게 기준은 다른 클래스가 얼마나 포함되어 있는지를 보는 것이다. 그리고 노드에서 gain(게인, 불순도)를 구할 수 있음. 클래스마다 불순도를 구할 수 있음. 불순도 최대 크기는 1임. 불순도는 낮을수록 좋다. 당연하다. 이득율이란 단어는 몇개의 클래스에 대해서 전체클래스에서 어떠한 비율로 얻었는지를 말함. 정보 이득 자체가 불순도 구하는거지. 지니계수는 정보 이득 구하기 전에 구함. 결정 트리에서 분할 속성을 선택하는 방식이지. 분할 속성이란? 수박 선명함 판별할 때 줄무늬가 서명함, 약간 흐림,  이 두가지가 분할 속성이다. 왜냐하면 더 나눌 수 있기 때문이다. 그런데 이렇게 나뉘는게 엄청 커지면(depth가 커짐) 오버 피팅과 같다. 데이터가 하나만 남는거지. leaf length가 길어지면(가지가 많아짐) 분류가 회귀로 변할 수 있음. 그러니까 나눌 의미가 없어지지. 지니계수는 분할의 기준이 됨(일정이상의 불순도일때 분할속성을 가진다는 전제 하에).  지니계수가 높으면 두개 뽑았을 때 다른 것일 확률이 높다는 의미임. 어쨌든 지니계수는 불순도를 확률적으로 구한다. 오버피팅을 방지하기위해 가지치기(프루닝)를 함. 가지치기는 얼리스탑과 같은 기능을 함. 검증 데이터셋을 통해 depth를 조정하여 오버피팅을 방지함. 정확도가 설정값을 넘어가면 가지치기를 중단하는거지. 깊이가 증가하지 않음. 가지는 지니계수나 gain을 통해 분할속성을 결정함. y=ax+b 에서 등호를 변화시켜 분할속성을 결저앟고 ab를 바꿔서 다시 가지에서 분할함. ab 바꾸는 갱신은 불순도로 결정함. 불순도 크면 ab도 크게 바꾼다. 그냥 트리가 선형 방정식 적용하면 이렇게 클래스를 나눈다는거임. 선형 방정식 방정식 여러개써서 복잡한 것도 나눌 수 있는거지. 불순도로 갱신하고. 선형 방정식이 여러개 쓰이면 곡선이 되고 그러면 복잡한 특징도 나눌 수 있지! 분할 속성은 분할할수 있는 노드를 말함.