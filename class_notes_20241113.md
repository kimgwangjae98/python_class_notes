에러같은거 나면 챗gpt나 클로드, 번역같은거 써서 찾아봐. 

가끔 차원의 저주를 받음. 차원이 높으면 특징 못뽑고 성능이 저조해짐. 그래서 차원 축소가 필요함. 3차원을 2차원으로, 2차원을 1차원으로 내리는 방법이지. 왜 필요하냐고? 차원이 높으면 데이터 밀도가 떨어지는데, 이를 해결하여 **데이터 밀도를 높이기 위해** 차원 축소를 사용한다. 그래서 차원의 저주에서 벗어날 수 있다.

저차원 공간(1D, 2D)에서는 데이터 포인트들이 상대적으로 가깝게 분포하지만, 차원이 증가할수록 고차원 공간에서는 데이터가 넓게 퍼지고 서로 멀어집니다. 이처럼 차원이 높아지면 데이터가 희박해져 분석과 패턴 인식이 어려워지는 현상을 시각적으로 표현한 것입니다.

k최근접 이웃은 가장 거리가 가까운 k개의 데이터의 결과를 이용해 다수결로 분류하는 방법.
**k-최근접 이웃 (k-NN)**은 새로운 데이터가 주어졌을 때, 그와 가장 가까운 k개의 데이터를 찾아 다수결을 통해 분류하거나 평균값을 내어 예측하는 알고리즘입니다. 간단한 예로, 반에서 새로운 학생이 어떤 그룹에 속할지 결정하려 한다고 가정해 봅시다. k를 3으로 설정하면, 새 학생과 가장 가까운 3명의 친구를 찾습니다. 만약 3명 중 2명이 "스포츠 그룹"이고 1명이 "음악 그룹"이라면, 새 학생도 스포츠 그룹으로 분류됩니다.

주성분 분석은 딥러닝에서도 나옴. 가장 자주 사용하는 차원 축소법임. 주성분은 주로 영향을 미치는 성분을 말함. 그냥 우리가 본 차원축소 그거임. 선이나 평면긋고 그곳에 투영하는거임. 점들이 특정 방향으로 분포해 있는 평면에 임의의 선을 긋고, 점들을 임의의 선에 투영했을 때의 모습을 보는거지. 투영된 점들이 최대한 많이 분산되어 서로 띄엄띄엄 되어야 좋다고함. 단, 차원을 축소하면서 원래 있던 위치 데이터가 소실될 수 있음. 어쩔수없다. 물론 잡음 제거도 가능하지... 덜 중요한 성분을 없애버리는거지. 잡음 제거 외에도 차원 축소, 특징 추출, 시각화도 할 수 있다.

커널이란 공간적으로 매핑한다는 소리임. 

매니폴드 학습은... 매니폴드는 국소적으로 유클리드 공간과 동형인 공간. 구 위의 삼각형은 내각합이 180도 이상인데, 국소적으로 보면 평면(유클리드 공간)으로 볼 수 있음. 그러니까 예시로 곡선을 엄청 확대하면 직선으로 보이는 거지. 

머신러닝에 회귀 분류 강화 이렇게 종류가 있고, 딥러닝도 회귀 분류 가오하 학습 이렇게 있음. 강화학습도 결정과정을 잘 꾸며야되지. 

소프트맥스는 알지? 그거임 ㅋㅋ