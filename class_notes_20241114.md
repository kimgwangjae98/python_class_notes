머신러닝 책이 어려움. 대학원생꺼라서 그럼. 개념만 해애앴음 나는. 이번달에 진도는 다 나갈꺼임. 자율주행에 캐즘? 어떠한 기술이 어떤 성숙도를 넘어갔을 때 정체기를 말함. 관련 지식들(컴공,전자,자동차공학 등)이 분산되어있어있음. 자율주행하는데 필요한 장비나 규칙들을 배워야됨. 러프하게 배우면됨. 우리 자율주행관련법에선 5천대 이상 자율주행차를 만들면 국내법이 적용됨. 수입차도 1만대 이상 팔면 적용되고. 현재 법률 제정 단계임. 현대가 만들고있음. 법률 때문에 지체되고있음. 사실 자동차법이 계속 바귀어러 러프하게 알려줄 수 밖에 없다. ROS도 배워야됨(로봇공학). 착실히 배운 사람이 100명도 채 안됨. 어떻게 가르칠지 감이 안잡힌다네.

오늘은 머신러닝 실습을 할 것임. 

머신 러닝으로 할 수 있는 데이터들은 어떠한 것이 있을까?
딥러닝하고 머신러닝을 구분하자면?

우선 머신러닝과 딥러닝을 구분하자면 '뉴럴 네크워크의 유무' 와 '데이터 특성 추출 자동 유무'
딥러닝은 뉴럴 네크워크를 쓰고 데이터 특성도 자동으로 추출해준다.
이것으로 머신러닝과 딥러닝의 데이터가 구분된다.
Q : 그러므로, 머신러닝으로 알맞은 데이터는 어떤 데이터일까?
A : 특징이 명확하게 구분되어있는 데이터. 즉 내가 어떠한 데이터에서 추출한 특징이 있는 데이터들을 사용할 수 있다.
EX : 병리학 데이터(피검사), 붓꽃 데이터, 보스턴 집값 데이터(특징이 명확한 데이터) -> 타블러 or 테이블 데이터 라고 부름. 
머신러닝에 쓸수있는 데이터가 이렇게 명확한 특징을 가진다. 딥러닝해도 정확도 비슷하지.

개발의 1순위 : 무엇을 사용해서 결과를 도출할 것인지(사용할 도구지정)
딥러닝은 특징을 정하기 어려울 때 사용함. 

우리는 병리학, 붓꽃, 집값 데이터로 머신러닝을 오늘 해볼것이다!

Q. 참고로 트레인 데이터셋과 테스트 데이터셋을 어덯게 나눠야할까?
A. 정규분포에 따라 나눠야한다. 대충 8:2 비율로 나뉜다.
-> 나누어주는 함수가 train_test 뭐시기가 스킬릿런에 잇음. 대
캐글이랑 aihub에서 찾아보자.

오늘은 머신러닝을 실습했다. 머신러닝을 파이썬으로 구동할려면 scikit-learn을 사용하면 된다.
임포트해서 쓰면 된다.
그리고 예제는 해당 모듈 홈페이지에 들어가서 찾아보면 된다. 붓꽃 데이터도 임포트 하면 된다. 대체로 이렇게 모듈로 데이터셋 불러오면 target으로 정답 레이블을 보고 data로 데이터셋을 자세히 볼수있다. 중요한 사항은 바로 **차원맞추기**이다. 데이터간의 차원을 맞추지 못하면 오류가 발생한다. 대체로 이 차원 맞추기에서 오류가 나기 때문에 데이터셋을 받아봤으면 data.shape 로 데이터의 형태를 필수적으로 봐야 한다. 그리고 feature_names로 어떤 특징의 이름을 알면 좋다. 

참고로 입력 데이터의 차원이 높으면(=특징 벡터가 많으면) 특징이 희미해져 제대로된 학습이 안될 수가 있다. 또한 시각화하여 데이터가 어떻게 생겨먹었는지도 이해하기 어렵다. 그렇기 때문에 차원축소라는 방법이 있다. 차원축소는 특징의 갯수를 줄여 차원을 줄이는 기법이다. 대표적으로 PCA 가 있고, 노이즈 제거와 새로운 특징을 뽑아낼 수 있지만 그 반대로 중요한 특징이 사라질 수 있다는 단점이 있다. 보면 분류할지, 회귀할지 볼 수 있다.

자고로 머신러닝할때 x_train을 X, y_train을 y로 각각 시험데이터랑 시험데이터의 라벨로 쓴다. 즉 특징들과 정답을 말한다. 이걸로 머신러닝 모델을 선정하고 모델을 학습시킨다. plot_tree 로 머신러닝 기법인 트리로 학습시켰을 때 어떻게 학습됬는지도 이미지로 볼 수 있다. 학습이 깊게 되면 트리가 엄청 길어지더라. 그리고 가끔 차원 안맞다고 오류를 띄우는데 오류창을 잘 읽자. 나같은 경우 한개를 넣어봣는데  if your data has a single feature or array.reshape(1, -1) if it contains a single sample. 이렇게 뜨고 reshape(1,-1) 붙여서 형식 다시 맞추니 됐다.

암도 머신러닝으로 판정할 수 있었다. 양성 음성 판정 단어가 저런걸 쓸줄은 몰랐다. 이것도 결정 트리로 학습시켜 구할 수 있었다. 그다음에 서포트 벡터 머신으로 학습할려고 train_test_split 으로 딥러닝에 쓰이는 4가지 변수로 시험 훈련 정답 레이블로 나누고 정규분포화시켰다. 이러면 더 잘된다네. 그담에 svc로 훈련. c는 분류의 약자다. 리포트, 매트릭스로 정답률을 대충은 알 수 있었는데, 매트릭스는 대각선에 값이 많아야 성능이 뛰어남을 뜻했다. 대체로 임의로 정답, 훈련 데이터 나누기 보다는 정규분포 함수 쓰는게 좋더라. 정답률이 엄청 올라.

보스턴 집값은 인종차별 문제로 내려갔다는데, 데이터가 인터넷에 남아있어 다행이다. 이건 csv파일 안에 특징이랑 정답이 함께 있어서 판다스로 직접 나눠야 했다. 이렇게 데이터 전처리를 해주는 과정이 있어야 했다. 또 이렇게 전처리를 해야하는 데이터가 실전에 엄청 많다고들 하셨고. 저거 정답 떼어내고 또 형식 맞추기로 콜론 때어내는 등 전처리가 번거로웠다. 데이터만 남기는게 힘들었고. 그 이후야 뭐 그냥 이전에 하던데로 결정트리인데 회귀할 때 쓰던 모델 선정해서 학습시키면 끝. 오차는 랜덤이라 잘 봐야한다. 클수도있고 낮을수도있다. 그리고 회귀문제는 성능평가를 정확도가 아니라 오차로 구한다. 불연속적인 값에서 어떻게 정확도를 구하겠는가. 참고로 오차 구하는것도 MSE, MAE든 간에 둘다 오차를 구하는거다. 성능 평가가 가능하지. 다만 두 성능 측정 기법을 비교하진 말자. 서로 다른 성능 평가 도구라 비교자체가 안된다. 둘중 하나가 값 낮다고 정확한거 아니야.

kaggle로 질병 탐지하는 것도 참... 데이터 정제가 잘 되어있는데 csv 파일에 열 갯수가 안맞아서 보니까 쉼도가 더 찍혀있네? 인터넷 찾아서 열 없애는 코드 불러와 적용시켜 전처리했다. 그거만 하면 땡이더라. 시험 데이터랑 훈련 데이터 파일이 나뉘어있었고 각 파일에 정답이랑 특징들이 함께 있어서 전처리했고. 이건 분류문제라 svc적용해서 풀었다. 사실 적용안하고 결정 트리써도 정답률이 96% 나오더라. svc이면 100%. 데이터가 이리 정확하니 어쩔수가 없다. 이래서 데이터 정제가 중요하다고 누누히 말하겠지.

포트폴리오 내용 그거 gui 만든거 그거는 ppt 있으니까 그걸로 만들어버리자. 그거는 글감이 풍부해진다.